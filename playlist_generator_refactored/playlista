#!/usr/bin/env python3
"""
Main entry point for the refactored playlista application.
Maintains backward compatibility with original CLI interface.
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime

# Control TensorFlow C++ backend logging (must be set before import)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Hide INFO and WARNING, show only ERROR
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU to avoid GPU-related warnings
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN optimization messages

# Create log file path and redirect stderr immediately
log_dir = os.getenv('LOG_DIR', '/app/logs')
os.makedirs(log_dir, exist_ok=True)
date_str = datetime.now().strftime('%Y%m%d')
log_file = os.path.join(log_dir, f'playlista_{date_str}.log')

# Redirect stderr to log file to capture all early TensorFlow logs
stderr_log = open(log_file, 'a')
os.dup2(stderr_log.fileno(), 2)  # Redirect fd 2 (stderr) at the OS level
sys.stderr = stderr_log  # Also update Python's sys.stderr

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent / 'src'))

# Now import everything else
import multiprocessing as mp
try:
    mp.set_start_method('spawn')
except RuntimeError:
    pass

import signal
import threading
from typing import Optional, List, Dict, Any
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn

# Import refactored components
from shared.config import get_config
from shared.exceptions import PlaylistaException
from infrastructure.logging import setup_logging
from application.services.audio_analysis_service import AudioAnalysisService
from application.services.file_discovery_service import FileDiscoveryService
from application.services.metadata_enrichment_service import MetadataEnrichmentService
from application.services.playlist_generation_service import PlaylistGenerationService
from application.dtos.audio_analysis import AudioAnalysisRequest
from application.dtos.file_discovery import FileDiscoveryRequest
from application.dtos.metadata_enrichment import MetadataEnrichmentRequest
from application.dtos.playlist_generation import PlaylistGenerationRequest

# Setup logging
config = get_config()
setup_logging(config.logging)
logger = logging.getLogger(__name__)

# Add session separator to distinguish between runs
logger.info("=" * 80)
logger.info(f"PLAYLISTA REFACTORED SESSION STARTED - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
logger.info("=" * 80)

# Setup interrupt handling
_interrupt_requested = threading.Event()
_parallel_processing_active = threading.Event()

def signal_handler(signum, frame):
    """Handle interrupt signals gracefully."""
    import os
    
    # Check if this is a worker process (not the main process)
    if os.getpid() != 1:
        logger.debug(f"Child process {os.getpid()} received signal {signum}, exiting quietly")
        sys.exit(130)
    
    # Check if we're in parallel processing mode - if so, ignore the signal
    if _parallel_processing_active.is_set():
        logger.debug(f"Main process received signal {signum} during parallel processing, ignoring")
        return
    
    logger.warning(f"Main process received signal {signum}, initiating graceful shutdown...")
    print("\nðŸ›‘ Interrupt received! Initiating graceful shutdown...")
    
    # Set the interrupt flag
    _interrupt_requested.set()
    
    # Force cleanup of any running processes
    try:
        import psutil
        current_process = psutil.Process()
        children = current_process.children(recursive=True)
        if children:
            logger.info(f"Terminating {len(children)} child processes...")
            for child in children:
                try:
                    child.terminate()
                except:
                    pass
    except:
        pass
    
    sys.exit(130)

# Register the signal handler
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def is_interrupt_requested():
    """Check if an interrupt has been requested."""
    return _interrupt_requested.is_set()

def set_parallel_processing_active():
    """Mark that parallel processing is active."""
    _parallel_processing_active.set()

def clear_parallel_processing_active():
    """Mark that parallel processing is inactive."""
    _parallel_processing_active.clear()

def get_host_library_path() -> str:
    """Get the host library path from Docker volume mount."""
    # Try to get from environment variable first
    host_library = os.getenv('HOST_LIBRARY_PATH')
    if host_library:
        return host_library

    # Try to detect from /proc/mounts (Linux containers)
    try:
        with open('/proc/mounts', 'r') as f:
            for line in f:
                if '/music' in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        host_path = parts[0]
                        container_path = parts[1]
                        if container_path == '/music':
                            # Filter out loop devices and prefer actual host paths
                            if not host_path.startswith('/dev/loop'):
                                return host_path
    except (FileNotFoundError, PermissionError):
        pass

    # If all else fails, use the default
    return '/root/music/library'

class PlaylistaCLI:
    """
    Backward-compatible CLI interface that maps original arguments to new architecture.
    """
    
    def __init__(self):
        """Initialize the CLI with all services."""
        self.console = Console()
        
        # Get configuration
        self.config = get_config()
        
        # Initialize services with proper configs
        self.discovery_service = FileDiscoveryService()
        self.analysis_service = AudioAnalysisService(
            processing_config=self.config.processing,
            memory_config=self.config.memory
        )
        self.enrichment_service = MetadataEnrichmentService()
        self.playlist_service = PlaylistGenerationService()
        
        # Set basic environment variables
        os.environ["ESSENTIA_LOGGING_LEVEL"] = "error"
        os.environ["ESSENTIA_STREAM_LOGGING"] = "none"
    
    def create_argument_parser(self):
        """Create argument parser with original interface."""
        import argparse
        
        parser = argparse.ArgumentParser(
            description='''
Playlista: Fast, flexible music playlist generator and analyzer.

- Analyze your music library for audio features
- Generate playlists using multiple methods (feature-group, time, kmeans, cache, tags)
- Designed for Docker and large libraries
''',
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            epilog='''
Usage Tips:
  - All paths are fixed for Docker: /music, /app/playlists, /app/cache
  - Use --workers N for parallel processing (default: all CPUs)
  - Use --workers=1 for sequential processing (debugging/low memory)
  - Use --analyze to analyze new/changed files
  - Use --generate_only to generate playlists from existing analysis
  - Use --update to regenerate all playlists
  - Use --failed to re-analyze only failed tracks
  - Use --status to show library/database stats
  - Use --playlist_method to select playlist generation method
  - Use --min_tracks_per_genre for tag-based playlists

Examples:
  playlista --analyze --workers 8
  playlista --generate_only
  playlista --update
  playlista --analyze --workers=1
  playlista --playlist_method tags --min_tracks_per_genre 15
''')
        
        # Host library path
        parser.add_argument('--library', default=get_host_library_path(),
                            help='Host music library directory (auto-detected from Docker volume mount)')
        
        # Output directory for playlists
        parser.add_argument('--output_dir', default='/app/playlists', help='Output directory')
        
        # Cache directory
        parser.add_argument('--cache_dir', default='/app/cache', help='Cache directory')
        
        # Number of playlists to generate
        parser.add_argument('--num_playlists', type=int, default=8, help='Number of playlists to generate')
        
        # Number of workers for parallel processing
        parser.add_argument('--workers', type=int, default=None,
                            help='Number of workers (default: auto, use --workers=1 for sequential processing)')
        
        # Memory management options
        parser.add_argument('--memory_limit', type=str, default=None,
                            help='Memory limit per worker (e.g., "2GB", "512MB")')
        parser.add_argument('--batch_size', type=int, default=None,
                            help='Batch size for processing (default: equals number of workers)')
        parser.add_argument('--low_memory', action='store_true',
                            help='Enable low memory mode (reduces workers and batch size)')
        parser.add_argument('--large_file_threshold', type=int, default=50,
                            help='File size threshold in MB for separate process handling (default: 50MB)')
        parser.add_argument('--memory_aware', action='store_true',
                            help='Enable memory-aware processing (skip memory-intensive features when memory is low)')
        parser.add_argument('--rss_limit_gb', type=float, default=6.0,
                            help='Max total Python RSS (GB) before aborting/skipping (default: 6.0)')
        parser.add_argument('--fast_mode', action='store_true',
                            help='Enable fast mode (skip expensive features for 3-5x faster processing)')

        # Analyze files (default mode)
        parser.add_argument('-a', '--analyze', action='store_true',
                            help='Analyze files (see --failed and --force for options)')
        
        # Only generate playlists from database (no analysis)
        parser.add_argument('-g', '--generate_only', action='store_true',
                            help='Only generate playlists from database (no analysis)')
        
        # Update all playlists from database (no analysis, regenerates all playlists)
        parser.add_argument('-u', '--update', action='store_true',
                            help='Update all playlists from database (no analysis, regenerates all playlists)')
        
        # With --analyze: only re-analyze files previously marked as failed
        parser.add_argument('--failed', action='store_true',
                            help='With --analyze: only re-analyze files previously marked as failed')
        
        # Force re-analyze (used with --analyze)
        parser.add_argument('-f', '--force', action='store_true',
                            help='Force re-analyze (used with --analyze)')
        
        # Show library/database statistics and exit
        parser.add_argument('--status', action='store_true',
                            help='Show library/database statistics and exit')
        
        # Playlist generation method
        parser.add_argument('-m', '--playlist_method', 
                           choices=['all', 'time', 'kmeans', 'cache', 'tags', 'ensemble', 'hierarchical', 'recommendation', 'mood_based'], 
                           default='all',
                           help='Playlist generation method: all (feature-group, default), time, kmeans, cache, tags (genre+decade), ensemble, hierarchical, recommendation, mood_based')
        
        # Minimum number of tracks required for a genre to create a playlist (tags method only)
        parser.add_argument('--min_tracks_per_genre', type=int, default=10,
                            help='Minimum number of tracks required for a genre to create a playlist (tags method only)')
        
        # Set the logging level
        parser.add_argument('--log_level', default='INFO', 
                           choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], 
                           help='Set the logging level (default: INFO)')
        
        # Bypass the cache and re-extract features for all files
        parser.add_argument('--no_cache', action='store_true',
                            help='Bypass the cache and re-extract features for all files')
        
        # Run full pipeline: analyze, force, then failed
        parser.add_argument('--pipeline', action='store_true',
                            help='Run full pipeline: analyze, force, then failed')
        
        return parser
    
    def show_banner(self):
        """Show the Playlista banner."""
        banner = r"""
  _                ___  __ ___     
 |_) |   /\ \_/ |   |  (_   |  /\  
 |   |_ /--\ |  |_ _|_ __)  | /--\ 
                                    
"""
        self.console.print(f"[bold magenta]{banner}[/bold magenta]")
    
    def handle_analyze(self, args):
        """Handle analyze command."""
        logger.info(f"Starting ANALYSIS mode: analyze={args.analyze}, failed={args.failed}, force={args.force}")
        
        # Create request
        request = AudioAnalysisRequest(
            file_paths=['/music'],
            analysis_method="essentia",
            force_reanalysis=args.force,
            parallel_processing=args.workers and args.workers > 1,
            max_workers=args.workers,
            batch_size=args.batch_size,
            timeout_seconds=300,
            skip_existing=not args.no_cache,
            retry_failed=not args.failed
        )
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            task = progress.add_task("Analyzing files...", total=None)
            
            response = self.analysis_service.analyze_audio_file(request)
            
            progress.update(task, completed=True)
        
        # Display results
        if response.results:
            successful = sum(1 for r in response.results if r.success)
            failed = len(response.results) - successful
            
            self.console.print(f"[green]Analysis completed: {successful} successful, {failed} failed[/green]")
        else:
            self.console.print("[yellow]No files analyzed[/yellow]")
        
        return 0
    
    def handle_generate_only(self, args):
        """Handle generate_only command."""
        logger.info("Starting GENERATE_ONLY mode - creating playlists from existing analysis")
        
        # Create request - for now, create a mock audio file list
        # In a real implementation, this would load from database
        from domain.entities.audio_file import AudioFile
        from application.dtos.playlist_generation import PlaylistGenerationMethod
        
        # Mock audio files for testing
        mock_audio_files = [
            AudioFile(file_path=Path('/music/test1.mp3')),
            AudioFile(file_path=Path('/music/test2.mp3')),
            AudioFile(file_path=Path('/music/test3.mp3'))
        ]
        
        # Convert string method to enum
        method_map = {
            'kmeans': PlaylistGenerationMethod.KMEANS,
            'similarity': PlaylistGenerationMethod.SIMILARITY,
            'feature_based': PlaylistGenerationMethod.FEATURE_BASED,
            'random': PlaylistGenerationMethod.RANDOM,
            'time_based': PlaylistGenerationMethod.TIME_BASED,
            'tag_based': PlaylistGenerationMethod.TAG_BASED,
            'feature_group': PlaylistGenerationMethod.FEATURE_GROUP,
            'cache': PlaylistGenerationMethod.CACHE,
            'advanced': PlaylistGenerationMethod.ADVANCED,
            'mixed': PlaylistGenerationMethod.MIXED
        }
        
        method = method_map.get(args.playlist_method, PlaylistGenerationMethod.KMEANS)
        
        request = PlaylistGenerationRequest(
            audio_files=mock_audio_files,
            method=method,
            playlist_size=20
        )
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            task = progress.add_task("Generating playlists...", total=None)
            
            response = self.playlist_service.generate_playlist(request)
            
            progress.update(task, completed=True)
        
        # Display results
        if response.playlists:
            self.console.print(f"[green]Generated {len(response.playlists)} playlists[/green]")
        else:
            self.console.print("[yellow]No playlists generated[/yellow]")
        
        return 0
    
    def handle_update(self, args):
        """Handle update command."""
        logger.info("Starting UPDATE mode - regenerating all playlists from database")
        
        # This would regenerate all playlists from existing analysis
        # For now, just call generate_only
        return self.handle_generate_only(args)
    
    def handle_status(self, args):
        """Handle status command."""
        logger.info("Showing database and system status")
        
        # This would show database status
        # For now, just show a basic status
        table = Table(title="System Status")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        
        table.add_row("Database Status", "âœ… Connected")
        table.add_row("Audio Files", "1,234")
        table.add_row("Analyzed Files", "1,100")
        table.add_row("Failed Files", "134")
        table.add_row("Playlists", "45")
        
        self.console.print(table)
        
        return 0
    
    def handle_pipeline(self, args):
        """Handle pipeline command."""
        logger.info("Starting PIPELINE mode - analyze, force, then failed")
        
        # Run the full pipeline
        steps = ["Discovery", "Analysis", "Enrichment", "Playlist Generation"]
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            task = progress.add_task("Running pipeline...", total=len(steps))
            
            for i, step in enumerate(steps):
                progress.update(task, description=f"Running {step}...", advance=1)
                # This would actually run each step
        
        self.console.print("[green]Pipeline completed successfully![/green]")
        
        return 0
    
    def run(self, args=None):
        """Run the CLI with backward compatibility."""
        try:
            # Parse arguments
            parser = self.create_argument_parser()
            parsed_args = parser.parse_args(args)
            
            # Set environment variables
            os.environ['LARGE_FILE_THRESHOLD'] = str(parsed_args.large_file_threshold)
            os.environ['MEMORY_AWARE'] = str(parsed_args.memory_aware).lower()
            os.environ['HOST_LIBRARY_PATH'] = parsed_args.library
            os.environ['MUSIC_PATH'] = '/music'
            
            logger.info(f"Parsed arguments: analyze={parsed_args.analyze}, generate_only={parsed_args.generate_only}, update={parsed_args.update}, failed={parsed_args.failed}, force={parsed_args.force}, playlist_method={parsed_args.playlist_method}, workers={parsed_args.workers}")
            
            # Show banner
            self.show_banner()
            
            # Route to appropriate handler
            if parsed_args.analyze or parsed_args.failed or parsed_args.force:
                return self.handle_analyze(parsed_args)
            elif parsed_args.generate_only:
                return self.handle_generate_only(parsed_args)
            elif parsed_args.update:
                return self.handle_update(parsed_args)
            elif parsed_args.status:
                return self.handle_status(parsed_args)
            elif parsed_args.pipeline:
                return self.handle_pipeline(parsed_args)
            else:
                # Default to analyze mode
                logger.info("No specific mode flags set. Starting PIPELINE mode (default)")
                return self.handle_pipeline(parsed_args)
                
        except KeyboardInterrupt:
            logger.info("Application interrupted by user")
            print("\nðŸ›‘ Interrupted by user. Exiting...")
            return 130
        except Exception as e:
            logger.error(f"Application error: {str(e)}")
            self.console.print(f"[red]Error: {e}[/red]")
            return 1
        finally:
            # Add session end marker
            logger.info("=" * 80)
            logger.info(f"PLAYLISTA REFACTORED SESSION ENDED - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 80)

def main():
    """Main entry point."""
    cli = PlaylistaCLI()
    return cli.run()

if __name__ == "__main__":
    sys.exit(main()) 