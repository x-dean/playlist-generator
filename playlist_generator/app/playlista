#!/usr/bin/env python3

import os
os.environ["GLOG_minloglevel"] = "3"  # Only FATAL
os.environ["GLOG_logtostderr"] = "1"
os.environ["GLOG_stderrthreshold"] = "3"

import essentia
essentia.log.infoActive = False
essentia.log.warningActive = False
essentia.log.errorActive = False

# --- Queue-based log handler for throttled output with color ---
import threading
import queue
import time
import logging
from colorlog import ColoredFormatter

log_queue = queue.Queue()

class QueueHandler(logging.Handler):
    def emit(self, record):
        try:
            msg = self.format(record)
            log_queue.put(msg)
        except Exception:
            pass

def log_consumer():
    while True:
        try:
            msg = log_queue.get(timeout=0.5)
            print(msg)
            time.sleep(0.05)  # Throttle: adjust as needed (e.g., 0.05s = 20 logs/sec)
        except queue.Empty:
            continue

queue_handler = QueueHandler()
color_formatter = ColoredFormatter(
    "%(log_color)s%(asctime)s %(levelname)-8s%(reset)s %(message)s",
    datefmt="%H:%M:%S",
    reset=True,
    log_colors={
        'DEBUG': 'cyan',
        'INFO': 'green',
        'WARNING': 'yellow',
        'ERROR': 'red',
        'CRITICAL': 'red,bg_white',
    },
    style='%'
)
queue_handler.setFormatter(color_formatter)
root_logger = logging.getLogger()
root_logger.handlers = [queue_handler]

threading.Thread(target=log_consumer, daemon=True).start()

import argparse
import sys
import time
import traceback
import multiprocessing as mp
from utils.logging_setup import setup_colored_logging
from utils.path_utils import convert_to_host_path
from music_analyzer.feature_extractor import AudioAnalyzer
from database.playlist_db import PlaylistDatabase
from music_analyzer.parallel import ParallelProcessor
from music_analyzer.sequential import SequentialProcessor
from playlist_generator.time_based import TimeBasedScheduler
from playlist_generator.kmeans import KMeansPlaylistGenerator
from playlist_generator.cache import CacheBasedGenerator
from playlist_generator.playlist_manager import PlaylistManager
import logging
from utils.cli import PlaylistGeneratorCLI, CLIContextManager
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.console import Console
from rich.panel import Panel
from utils.checkpoint import CheckpointManager
from typing import Optional
import multiprocessing
import threading
from rich.live import Live
from rich.spinner import Spinner

logger = setup_colored_logging()

import logging as pylogging
pylogging.getLogger("musicbrainzngs").setLevel(pylogging.WARNING)

# Initialize system monitoring
# Remove SystemMonitor and monitor_performance imports
# Remove @monitor_performance decorators from get_audio_files and main
# Remove system_monitor initialization
checkpoint_manager = CheckpointManager()

# Initialize CLI
cli = PlaylistGeneratorCLI()

os.environ["ESSENTIA_LOGGING_LEVEL"] = "error"
os.environ["ESSENTIA_STREAM_LOGGING"] = "none"

cache_dir = os.getenv('CACHE_DIR', '/app/cache')
logfile_path = os.path.join(cache_dir, 'essentia_stderr.log')
logfile = open(logfile_path, 'w')
os.dup2(logfile.fileno(), 2)  # Redirect fd 2 (stderr) at the OS level
sys.stderr = logfile  # Also update Python's sys.stderr

def get_audio_files(music_dir: str) -> list[str]:
    """Recursively find all audio files in the given directory.

    Args:
        music_dir (str): Path to the music directory.

    Returns:
        list[str]: List of audio file paths.
    """
    file_list = []
    valid_ext = ('.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.opus')
    
    for root, _, files in os.walk(music_dir):
        for file in files:
            file_lower = file.lower()
            if file_lower.endswith(valid_ext):
                file_list.append(os.path.join(root, file))
    
    logger.info(f"Found {len(file_list)} audio files in {music_dir}")
    return file_list

def save_playlists(playlists: dict[str, dict], output_dir: str, library: str, music: str, failed_files: list[str], playlist_method: Optional[str] = None) -> None:
    """Saves generated playlists to disk.

    Args:
        playlists (dict[str, dict]): Dictionary of playlist names to their data.
        output_dir (str): Root output directory.
        library (str): Path to the host's music directory.
        music (str): Path to the container's music directory.
        failed_files (list[str]): List of failed file paths.
        playlist_method (str | None): The method used to generate playlists (e.g., 'time', 'kmeans').
    """
    # For time-based, create subfolders per slot
    def get_time_slot_from_name(name: str) -> str | None:
        if name.startswith("TimeSlot_"):
            slot_part = name[len("TimeSlot_"):]
            if "_Part" in slot_part:
                slot = slot_part.split("_Part")[0]
            else:
                slot = slot_part
            return slot
        return None

    saved_count = 0
    for name, playlist_data in playlists.items():
        if 'tracks' not in playlist_data or not playlist_data['tracks']:
            continue

        # Determine output path
        playlist_out_dir = output_dir
        if playlist_method == 'time':
            slot = get_time_slot_from_name(name)
            if slot:
                playlist_out_dir = os.path.join(output_dir, slot)
        os.makedirs(playlist_out_dir, exist_ok=True)

        host_songs = [
            convert_to_host_path(song, library, music)
            for song in playlist_data['tracks']
        ]
        playlist_path = os.path.join(playlist_out_dir, f"{name}.m3u")
        with open(playlist_path, 'w') as f:
            f.write("\n".join(host_songs))
        saved_count += 1
        logger.debug(f"Saved {name} with {len(host_songs)} tracks to {playlist_path}")

    # Save failed files (keep at root of method dir)
    os.makedirs(output_dir, exist_ok=True)
    if failed_files:
        failed_path = os.path.join(output_dir, "Failed_Files.m3u")
        with open(failed_path, 'w') as f:
            host_failed = [
                convert_to_host_path(p, library, music)
                for p in failed_files
            ]
            f.write("\n".join(host_failed))
        logger.info(f"Saved {len(failed_files)} failed files to {failed_path}")

from music_analyzer.analysis_manager import run_analysis, run_pipeline
import signal

def main() -> None:
    """Main entry point for the Playlista CLI application."""
    # Clear the terminal screen only if running interactively
    import sys
    if sys.stdout.isatty():
        os.system('cls' if os.name == 'nt' else 'clear')
    # Print Playlista ASCII art banner
    banner = r"""
  _                ___  __ ___     
 |_) |   /\ \_/ |   |  (_   |  /\  
 |   |_ /--\ |  |_ _|_ __)  | /--\ 
                                    
"""
    # ArgumentParser setup must come first
    parser = argparse.ArgumentParser(
        description='''
Playlista: Fast, flexible music playlist generator and analyzer.

- Analyze your music library for audio features
- Generate playlists using multiple methods (feature-group, time, kmeans, cache, tags)
- Designed for Docker and large libraries
''',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        epilog='''
Usage Tips:
  - All paths are fixed for Docker: /music, /app/playlists, /app/cache
  - Use --workers N for parallel processing (default: all CPUs)
  - Use --force_sequential for single-threaded (debugging/low memory)
  - Use --analyze to analyze new/changed files
  - Use --generate_only to generate playlists from existing analysis
  - Use --update to regenerate all playlists
  - Use --failed to re-analyze only failed tracks
  - Use --status to show library/database stats
  - Use --playlist_method to select playlist generation method
  - Use --min_tracks_per_genre for tag-based playlists

Examples:
  playlista --analyze --workers 8
  playlista --generate_only
  playlista --update
  playlista --force_sequential
  playlista --playlist_method tags --min_tracks_per_genre 15
''')
    # -h/--help is available by default in argparse
    # Remove --music_dir argument
    # Rename --library to --library
    parser.add_argument('--library', default='/music', help='Music library directory (default: /music)')
    # Output directory for playlists
    parser.add_argument('--output_dir', default='/app/playlists', help='Output directory')
    # Cache directory
    parser.add_argument('--cache_dir', default='/app/cache', help='Cache directory')
    # Number of playlists to generate
    parser.add_argument('--num_playlists', type=int, default=8, help='Number of playlists to generate')
    # Number of workers for parallel processing
    parser.add_argument('--workers', type=int, default=None, help='Number of workers (default: auto)')
    # Force sequential (single-threaded) processing
    parser.add_argument('--force_sequential', action='store_true', help='Force sequential processing (disables multiprocessing)')
    # Analyze files (default mode)
    parser.add_argument('-a', '--analyze', action='store_true', help='Analyze files (see --failed and --force for options)')
    # Only generate playlists from database (no analysis)
    parser.add_argument('-g', '--generate_only', action='store_true', help='Only generate playlists from database (no analysis)')
    # Update all playlists from database (no analysis, regenerates all playlists)
    parser.add_argument('-u', '--update', action='store_true', help='Update all playlists from database (no analysis, regenerates all playlists)')
    # With --analyze: only re-analyze files previously marked as failed
    parser.add_argument('--failed', action='store_true', help='With --analyze: only re-analyze files previously marked as failed')
    # Force re-analyze (used with --analyze)
    parser.add_argument('-f', '--force', action='store_true', help='Force re-analyze (used with --analyze)')
    # Show library/database statistics and exit
    parser.add_argument('--status', action='store_true', help='Show library/database statistics and exit')
    # Resume from last checkpoint if available
    parser.add_argument('--resume', action='store_true', help='Resume from last checkpoint if available')
    # Playlist generation method
    parser.add_argument('-m', '--playlist_method', choices=['all', 'time', 'kmeans', 'cache', 'tags'], default='all',
                      help='Playlist generation method: all (feature-group, default), time, kmeans, cache, or tags (genre+decade)')
    # Minimum number of tracks required for a genre to create a playlist (tags method only)
    parser.add_argument('--min_tracks_per_genre', type=int, default=10, help='Minimum number of tracks required for a genre to create a playlist (tags method only)')
    # Set the logging level
    parser.add_argument('--log_level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Set the logging level (default: INFO)')
    # Bypass the cache and re-extract features for all files
    parser.add_argument('--no_cache', action='store_true', help='Bypass the cache and re-extract features for all files')
    # Run full pipeline: analyze, force, then failed
    parser.add_argument('--pipeline', action='store_true', help='Run full pipeline: analyze, force, then failed')

    args = parser.parse_args()

    cache_dir = os.getenv('CACHE_DIR', '/app/cache')
    cache_file = os.path.join(cache_dir, 'audio_analysis.db')

    console = Console()
    console.print(f"[bold magenta]{banner}[/bold magenta]")
    total_files = len(get_audio_files(args.library))
    audio_db = AudioAnalyzer(cache_file, library=args.library, music='/music')
    total_in_db = len(audio_db.get_all_features())
    console.print(f"[cyan]Total music files found in library:[/cyan] [bold]{total_files}[/bold]")
    console.print(f"[cyan]Total tracks in database:[/cyan] [bold]{total_in_db}[/bold]")

    if args.pipeline:
        from music_analyzer.analysis_manager import run_pipeline
        # Initialize audio_db and playlist_db for pipeline
        audio_db = AudioAnalyzer(cache_file, library=args.library, music='/music')
        playlist_db = PlaylistDatabase(cache_file)
        run_pipeline(args, audio_db, playlist_db, cli)
        sys.exit(0)

    stop_event = multiprocessing.Event()
    def handle_sigint(signum, frame):
        print("\nReceived SIGINT (Ctrl+C), stopping gracefully...")
        stop_event.set()
    signal.signal(signal.SIGINT, handle_sigint)

    # Set logging level from CLI
    logger.setLevel(getattr(pylogging, args.log_level.upper(), pylogging.WARNING))
    os.environ['LOG_LEVEL'] = args.log_level.upper()

    # If --status is set, show statistics and exit
    if getattr(args, 'status', False):
        stats = playlist_db.get_library_statistics()
        # Add failed/skipped files count
        audio_db = AudioAnalyzer(cache_file)
        skipped_count = len([f for f in audio_db.get_all_features(include_failed=True) if f['failed']])
        stats['skipped_failed'] = skipped_count
        cli.show_library_statistics(stats)
        sys.exit(0)

    # If no mutually exclusive mode is set, default to analyze_only
    if not (args.analyze or args.failed or args.update):
        args.analyze = True

    # Robust mode selection
    sequential_mode = args.force_sequential or (args.workers is not None and int(args.workers) == 1)

    # If sequential mode is forced, always use 1 worker and warn if user set more
    if args.force_sequential:
        if args.workers is not None and int(args.workers) != 1:
            logger.warning("Both --force_sequential and --workers > 1 set. Forcing sequential mode with 1 worker.")
        args.workers = 1

    # Show configuration
    # Remove the call to cli.show_config
    
    # Initialize components
    audio_db = AudioAnalyzer(cache_file, library=args.library, music='/music')
    # Pass min_tracks_per_genre to PlaylistManager if using tags method
    if args.playlist_method == 'tags':
        playlist_manager = PlaylistManager(
            cache_file, args.playlist_method, min_tracks_per_genre=args.min_tracks_per_genre)
    else:
        playlist_manager = PlaylistManager(cache_file, args.playlist_method)
    
    music = '/music'
    library = args.library
    failed_files = []

    if not os.path.exists(args.library):
        cli.show_error(f"Music directory not found: {args.library}")
        sys.exit(1)

    start_time = time.time()
    try:
        # Try to resume from checkpoint
        if args.resume:
            state = checkpoint_manager.get_recovery_state()
            if state:
                cli.update_status("Resuming from checkpoint")
                failed_files = state.get('failed_files', [])
                if 'progress' in state:
                    cli.update_status(f"Resuming from {state['progress']} stage")

        # Clean up database
        missing_in_db = audio_db.cleanup_database()
        if missing_in_db:
            cli.show_warning(f"Removed {len(missing_in_db)} missing files from database")
            failed_files.extend(missing_in_db)

        # If --pipeline is set, run the full pipeline and exit
        if getattr(args, 'pipeline', False):
            run_pipeline(args, audio_db, playlist_db, cli, stop_event=stop_event)
            sys.exit(0)

        # Create a multiprocessing manager queue for long-running file notifications
        manager = multiprocessing.Manager()
        status_queue = manager.Queue()
        long_running_files = set()
        spinner_stop = threading.Event()

        def spinner_panel():
            if not long_running_files:
                return Panel("All files are processing normally.", title="Long-Running Files", border_style="green")
            return Panel(
                "\n".join([f"[yellow]{file}[/yellow]" for file in long_running_files]),
                title="[cyan]Long-Running Files (>5s) [spinner]",
                border_style="yellow"
            )

        def status_listener():
            while not spinner_stop.is_set():
                try:
                    filepath = status_queue.get(timeout=0.5)
                    long_running_files.add(filepath)
                except Exception:
                    continue

        listener_thread = threading.Thread(target=status_listener, daemon=True)
        listener_thread.start()

        if args.update:
            cli.update_status("Running in UPDATE mode")
            features_from_db = audio_db.get_all_features()
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
            # Show playlist statistics
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            # Save playlists to DB and to disk
            playlist_db.save_playlists(all_playlists)
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method)

        elif args.analyze or args.failed or args.force:
            failed_files = run_analysis(args, audio_db, playlist_db, cli, stop_event=stop_event, force_reextract=args.no_cache)

        elif args.generate_only:
            cli.update_status("Generating playlists from database")
            features_from_db = audio_db.get_all_features()
            
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
            
            # Show playlist statistics
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            
            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method)

        else:
            cli.update_status("Running full processing pipeline")
            file_list = get_audio_files(args.library)
            file_list = [convert_to_host_path(f, library, music) for f in file_list]
            
            # Analysis phase
            with CLIContextManager(cli, len(file_list), "[cyan]Analyzing audio files...") as (progress, task_id):
                processor = ParallelProcessor() if not sequential_mode else SequentialProcessor()
                workers = args.workers or max(1, mp.cpu_count())
                
                for i, features in enumerate(processor.process(file_list, workers)):
                    # Show only the filename in the progress bar
                    if isinstance(features, tuple):
                        # SequentialProcessor yields (features, filepath)
                        _, filepath = features
                    else:
                        # ParallelProcessor yields features only, can't get filename
                        filepath = file_list[i] if i < len(file_list) else ""
                    filename = os.path.basename(filepath)
                    progress.update(task_id, advance=1, description=f"Analyzing: {filename} ({i+1}/{len(file_list)})")
                    if stop_event.is_set():
                        print("\nInterrupted by user. Exiting...")
                        sys.exit(130)
                
                failed_files.extend(processor.failed_files)
            
            # Generation phase
            features_from_db = audio_db.get_all_features()
            
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                if stop_event.is_set():
                    print("\nInterrupted by user. Exiting...")
                    sys.exit(130)
            
            # Show playlist statistics
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            
            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method)

        # Show failed files if any
        if failed_files:
            cli.show_file_errors(failed_files)

    except Exception as e:
        cli.show_error(str(e), details=traceback.format_exc())
        
        # Save error state
        checkpoint_manager.save_checkpoint({
            'stage': 'error',
            'error': str(e),
            'traceback': traceback.format_exc(),
            'failed_files': failed_files
        }, name='error_state')
        
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nInterrupted by user. Exiting...")
        stop_event.set()
        sys.exit(130)
    finally:
        # Only print summary for generate/update modes (not analyze_only)
        if not args.analyze:
            try:
                features_from_db = audio_db.get_all_features()
                total_files = len(features_from_db)
                failed_count = len(failed_files)
                mb_count = 0
                no_mb_count = 0
                for f in features_from_db:
                    meta = f.get('metadata', {})
                    if meta.get('musicbrainz_id'):
                        mb_count += 1
                    else:
                        no_mb_count += 1
                runtime = time.time() - start_time
                logger.debug(f"Processed Files: {total_files}")
                logger.debug(f"Failed Files: {failed_count}")
                logger.debug(f"With MusicBrainz Info: {mb_count}")
                logger.debug(f"Without MusicBrainz Info: {no_mb_count}")
                logger.debug(f"Runtime: {runtime:.1f} seconds")
            except Exception as e:
                logger.debug(f"Error generating summary: {e}")

if __name__ == "__main__":
    main()