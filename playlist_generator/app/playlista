#!/usr/bin/env python3
"""
Main entry point for the playlist generator application.
"""

import sys
import os
import argparse
from datetime import datetime

# Add the app directory to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Parse --log_level early to set LOG_LEVEL env var
pre_parser = argparse.ArgumentParser(add_help=False)
pre_parser.add_argument('--log_level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'])
pre_args, _ = pre_parser.parse_known_args(sys.argv[1:])
os.environ['LOG_LEVEL'] = pre_args.log_level

# Setup colored file logging
from utils.logging_setup import setup_colored_file_logging

# Create log file path
log_dir = os.getenv('LOG_DIR', '/app/logs')
os.makedirs(log_dir, exist_ok=True)
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
log_file = os.path.join(log_dir, f'playlista_{timestamp}.log')

# Setup colored logging to file only
setup_colored_file_logging(log_file)

import logging
logger = logging.getLogger(__name__)

import essentia
essentia.log.infoActive = False
essentia.log.warningActive = False
essentia.log.errorActive = False

# Logging is already set up above with setup_colored_file_logging(log_file)

import argparse
import sys
import time
import traceback
import multiprocessing as mp
from utils.logging_setup import setup_colored_logging, setup_queue_colored_logging
from utils.path_utils import convert_to_host_path
from utils.path_converter import PathConverter
from music_analyzer.feature_extractor import AudioAnalyzer
from database.playlist_db import PlaylistDatabase
from music_analyzer.parallel import ParallelProcessor
from music_analyzer.sequential import SequentialProcessor
from playlist_generator.time_based import TimeBasedScheduler
from playlist_generator.kmeans import KMeansPlaylistGenerator
from playlist_generator.cache import CacheBasedGenerator
from playlist_generator.playlist_manager import PlaylistManager
import logging
from utils.cli import PlaylistGeneratorCLI, CLIContextManager
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.console import Console
from rich.panel import Panel
from typing import Optional, List, Dict, Any
import multiprocessing
import threading
from rich.live import Live
from rich.spinner import Spinner

# Logging already set up above

import logging as pylogging
pylogging.getLogger("musicbrainzngs").setLevel(pylogging.WARNING)

def get_host_library_path() -> str:
    """Get the host library path from Docker volume mount."""
    # Try to get from environment variable first
    host_library = os.getenv('HOST_LIBRARY_PATH')
    if host_library:
        return host_library
    
    # Try to detect from /proc/mounts (Linux containers)
    try:
        with open('/proc/mounts', 'r') as f:
            for line in f:
                if '/music' in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        host_path = parts[0]
                        container_path = parts[1]
                        if container_path == '/music':
                            # Filter out loop devices and prefer actual host paths
                            if not host_path.startswith('/dev/loop'):
                                return host_path
                            # If we only find loop devices, try to resolve the real path
                            elif host_path.startswith('/dev/loop'):
                                # Try to get the real path from the loop device
                                try:
                                    import subprocess
                                    result = subprocess.run(['losetup', '-l'], 
                                                          capture_output=True, text=True, timeout=5)
                                    if result.returncode == 0:
                                        for losetup_line in result.stdout.splitlines():
                                            if host_path in losetup_line:
                                                # Extract the backing file path
                                                parts = losetup_line.split()
                                                if len(parts) >= 7:  # Format: device backing_file
                                                    backing_file = parts[5]
                                                    # Extract the directory part
                                                    if '/music' in backing_file:
                                                        # Find the host path by removing the container path
                                                        host_dir = backing_file.replace('/music', '').rstrip('/')
                                                        if host_dir:
                                                            return host_dir
                                except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
                                    pass
    except (FileNotFoundError, PermissionError):
        pass
    
    # Try to get from Docker inspect (if available)
    try:
        import subprocess
        result = subprocess.run(['docker', 'inspect', '--format', '{{.Mounts}}', 'playlista'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            # Parse the mount information
            mounts = result.stdout.strip()
            if '/music' in mounts:
                # Extract the host path from the mount info
                import re
                match = re.search(r'([^:]+):/music', mounts)
                if match:
                    return match.group(1)
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
        pass
    
    # Try to get from /proc/self/mountinfo (more detailed mount info)
    try:
        with open('/proc/self/mountinfo', 'r') as f:
            for line in f:
                if '/music' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        # Format: ID MAJOR:MINOR ROOT MOUNT_POINT OPTIONS
                        mount_point = parts[4]
                        if mount_point == '/music':
                            # The host path is in the root field (parts[3])
                            # But we need to resolve it properly
                            root_path = parts[3]
                            # This is complex - let's try a different approach
                            pass
    except (FileNotFoundError, PermissionError):
        pass
    
    # If all else fails, use the default
    return '/root/music/library'

# Initialize CLI
cli = PlaylistGeneratorCLI()

os.environ["ESSENTIA_LOGGING_LEVEL"] = "error"
os.environ["ESSENTIA_STREAM_LOGGING"] = "none"

cache_dir = os.getenv('CACHE_DIR', '/app/cache')
logfile_path = '/app/logs/playlista.log'
logfile = open(logfile_path, 'a')
os.dup2(logfile.fileno(), 2)  # Redirect fd 2 (stderr) at the OS level
sys.stderr = logfile  # Also update Python's sys.stderr

def get_audio_files(music_dir: str) -> List[str]:
    """Recursively find all audio files in the given directory.

    Args:
        music_dir (str): Path to the music directory.

    Returns:
        List[str]: List of audio file paths.
    """
    file_list = []
    valid_ext = ('.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.opus')
    
    for root, _, files in os.walk(music_dir):
        for file in files:
            file_lower = file.lower()
            if file_lower.endswith(valid_ext):
                file_list.append(os.path.join(root, file))
    
    logger.info(f"Found {len(file_list)} audio files in {music_dir}")
    return file_list

def save_playlists(playlists: Dict[str, Dict[str, Any]], output_dir: str, library: str, music: str, failed_files: List[str], playlist_method: Optional[str] = None, host_library: str = None) -> None:

    """Saves generated playlists to disk.

    Args:
        playlists (Dict[str, Dict[str, Any]]): Dictionary of playlist names to their data.
        output_dir (str): Root output directory.
        library (str): Path to the host's music directory.
        music (str): Path to the container's music directory.
        failed_files (List[str]): List of failed file paths.
        playlist_method (str | None): The method used to generate playlists (e.g., 'time', 'kmeans').
        host_library (str | None): Host library path for path conversion.
    """
    # For time-based, create subfolders per slot
    def get_time_slot_from_name(name: str) -> Optional[str]:
        if name.startswith("TimeSlot_"):
            slot_part = name[len("TimeSlot_"):]
            if "_Part" in slot_part:
                slot = slot_part.split("_Part")[0]
            else:
                slot = slot_part
            return slot
        return None

    # Initialize path converter
    path_converter = PathConverter(host_library or library, '/music')
    
    saved_count = 0
    for name, playlist_data in playlists.items():
        if 'tracks' not in playlist_data or not playlist_data['tracks']:
            continue

        # Determine output path
        playlist_out_dir = output_dir
        if playlist_method == 'time':
            slot = get_time_slot_from_name(name)
            if slot:
                playlist_out_dir = os.path.join(output_dir, slot)
        os.makedirs(playlist_out_dir, exist_ok=True)


        
        # Convert container paths to host paths using the path converter
        host_songs = path_converter.convert_playlist_tracks(playlist_data['tracks'])
        playlist_path = os.path.join(playlist_out_dir, f"{name}.m3u")
        with open(playlist_path, 'w') as f:
            f.write("\n".join(host_songs))
        saved_count += 1
        logger.debug(f"Saved {name} with {len(host_songs)} tracks to {playlist_path}")

    # Save failed files (keep at root of method dir)
    os.makedirs(output_dir, exist_ok=True)
    if failed_files:
        failed_path = os.path.join(output_dir, "Failed_Files.m3u")
        with open(failed_path, 'w') as f:
            host_failed = path_converter.convert_failed_files(failed_files)
            f.write("\n".join(host_failed))
        logger.info(f"Saved {len(failed_files)} failed files to {failed_path}")

from music_analyzer.analysis_manager import run_analysis, run_pipeline
import signal

def main() -> None:
    """Main entry point for the Playlista CLI application."""
    logger.info("Starting Playlista application")
    
    # Clear the terminal screen only if running interactively
    import sys
    if sys.stdout.isatty():
        os.system('cls' if os.name == 'nt' else 'clear')
    # Print Playlista ASCII art banner
    banner = r"""
  _                ___  __ ___     
 |_) |   /\ \_/ |   |  (_   |  /\  
 |   |_ /--\ |  |_ _|_ __)  | /--\ 
                                    
"""
    # ArgumentParser setup must come first
    parser = argparse.ArgumentParser(
        description='''
Playlista: Fast, flexible music playlist generator and analyzer.

- Analyze your music library for audio features
- Generate playlists using multiple methods (feature-group, time, kmeans, cache, tags)
- Designed for Docker and large libraries
''',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        epilog='''
Usage Tips:
  - All paths are fixed for Docker: /music, /app/playlists, /app/cache
  - Use --workers N for parallel processing (default: all CPUs)
  - Use --force_sequential for single-threaded (debugging/low memory)
  - Use --analyze to analyze new/changed files
  - Use --generate_only to generate playlists from existing analysis
  - Use --update to regenerate all playlists
  - Use --failed to re-analyze only failed tracks
  - Use --status to show library/database stats
  - Use --playlist_method to select playlist generation method
  - Use --min_tracks_per_genre for tag-based playlists

Examples:
  playlista --analyze --workers 8
  playlista --generate_only
  playlista --update
  playlista --force_sequential
  playlista --playlist_method tags --min_tracks_per_genre 15
''')
    # -h/--help is available by default in argparse
    # Remove --music_dir argument
    # Rename --library to --library
    parser.add_argument('--library', default=get_host_library_path(), help='Host music library directory (auto-detected from Docker volume mount)')
    # Output directory for playlists
    parser.add_argument('--output_dir', default='/app/playlists', help='Output directory')
    # Cache directory
    parser.add_argument('--cache_dir', default='/app/cache', help='Cache directory')
    # Number of playlists to generate
    parser.add_argument('--num_playlists', type=int, default=8, help='Number of playlists to generate')
    # Number of workers for parallel processing
    parser.add_argument('--workers', type=int, default=None, help='Number of workers (default: auto)')
    # Force sequential (single-threaded) processing
    parser.add_argument('--force_sequential', action='store_true', help='Force sequential processing (disables multiprocessing)')
    # Analyze files (default mode)
    parser.add_argument('-a', '--analyze', action='store_true', help='Analyze files (see --failed and --force for options)')
    # Only generate playlists from database (no analysis)
    parser.add_argument('-g', '--generate_only', action='store_true', help='Only generate playlists from database (no analysis)')
    # Update all playlists from database (no analysis, regenerates all playlists)
    parser.add_argument('-u', '--update', action='store_true', help='Update all playlists from database (no analysis, regenerates all playlists)')
    # With --analyze: only re-analyze files previously marked as failed
    parser.add_argument('--failed', action='store_true', help='With --analyze: only re-analyze files previously marked as failed')
    # Force re-analyze (used with --analyze)
    parser.add_argument('-f', '--force', action='store_true', help='Force re-analyze (used with --analyze)')
    # Show library/database statistics and exit
    parser.add_argument('--status', action='store_true', help='Show library/database statistics and exit')
    # Playlist generation method
    parser.add_argument('-m', '--playlist_method', choices=['all', 'time', 'kmeans', 'cache', 'tags'], default='all',
                      help='Playlist generation method: all (feature-group, default), time, kmeans, cache, or tags (genre+decade)')
    # Minimum number of tracks required for a genre to create a playlist (tags method only)
    parser.add_argument('--min_tracks_per_genre', type=int, default=10, help='Minimum number of tracks required for a genre to create a playlist (tags method only)')
    # Set the logging level
    parser.add_argument('--log_level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Set the logging level (default: INFO)')
    # Bypass the cache and re-extract features for all files
    parser.add_argument('--no_cache', action='store_true', help='Bypass the cache and re-extract features for all files')
    # Run full pipeline: analyze, force, then failed
    parser.add_argument('--pipeline', action='store_true', help='Run full pipeline: analyze, force, then failed')

    args = parser.parse_args()
    logger.info(f"Parsed arguments: analyze={args.analyze}, generate_only={args.generate_only}, update={args.update}, failed={args.failed}, force={args.force}, playlist_method={args.playlist_method}, workers={args.workers}, force_sequential={args.force_sequential}")

    cache_dir = os.getenv('CACHE_DIR', '/app/cache')
    cache_file = os.path.join(cache_dir, 'audio_analysis.db')
    logger.debug(f"Using cache file: {cache_file}")

    console = Console()
    console.print(f"[bold magenta]{banner}[/bold magenta]")
    
    logger.info("Scanning music library for audio files")
    total_files = len(get_audio_files('/music'))
    logger.info(f"Found {total_files} audio files in library")
    
    # Initialize playlist_db and audio_db early for all modes
    logger.debug("Initializing database connections")
    playlist_db = PlaylistDatabase(cache_file)
    # AudioAnalyzer needs host library path for database storage, container music path for conversion
    audio_db = AudioAnalyzer(cache_file, library=args.library, music='/music')
    logger.debug("Database connections initialized")
    
    total_in_db = len(audio_db.get_all_features())
    logger.info(f"Database contains {total_in_db} analyzed tracks")
    console.print(f"[cyan]Total music files found in library:[/cyan] [bold]{total_files}[/bold]")
    console.print(f"[cyan]Total tracks in database:[/cyan] [bold]{total_in_db}[/bold]")

    if args.pipeline:
        logger.info("Starting pipeline mode")
        from music_analyzer.analysis_manager import run_pipeline
        run_pipeline(args, audio_db, playlist_db, cli)
        logger.info("Pipeline mode completed")
        sys.exit(0)

    stop_event = multiprocessing.Event()
    def handle_sigint(signum, frame):
        logger.info("Received SIGINT (Ctrl+C), stopping gracefully...")
        print("\nReceived SIGINT (Ctrl+C), stopping gracefully...")
        stop_event.set()
    signal.signal(signal.SIGINT, handle_sigint)

    # Set logging level from CLI
    logger.setLevel(getattr(pylogging, args.log_level.upper(), pylogging.WARNING))
    os.environ['LOG_LEVEL'] = args.log_level.upper()
    logger.debug(f"Logging level set to: {args.log_level.upper()}")

    # If --status is set, show statistics and exit
    if getattr(args, 'status', False):
        logger.info("Status mode: displaying library statistics")
        stats = playlist_db.get_library_statistics()
        # Add failed/skipped files count
        skipped_count = len([f for f in audio_db.get_all_features(include_failed=True) if f['failed']])
        stats['skipped_failed'] = skipped_count
        cli.show_library_statistics(stats)
        logger.info("Status display completed")
        sys.exit(0)

    # If no mutually exclusive mode is set, default to analyze_only
    if not (args.analyze or args.failed or args.update or args.generate_only):
        args.analyze = True
        logger.info("No execution mode specified, defaulting to analyze mode")

    # Robust mode selection
    sequential_mode = args.force_sequential or (args.workers is not None and int(args.workers) == 1)
    logger.info(f"Processing mode: {'sequential' if sequential_mode else 'parallel'}")

    # If sequential mode is forced, always use 1 worker and warn if user set more
    if args.force_sequential:
        if args.workers is not None and int(args.workers) != 1:
            logger.warning("Both --force_sequential and --workers > 1 set. Forcing sequential mode with 1 worker.")
        args.workers = 1

    # Show configuration
    # Remove the call to cli.show_config
    
    # Initialize playlist manager
    # Pass min_tracks_per_genre to PlaylistManager if using tags method
    logger.info(f"Initializing playlist manager with method: {args.playlist_method}")
    if args.playlist_method == 'tags':
        playlist_manager = PlaylistManager(
            cache_file, args.playlist_method, min_tracks_per_genre=args.min_tracks_per_genre)
        logger.debug(f"Using tag-based playlist generation with min_tracks_per_genre: {args.min_tracks_per_genre}")
    else:
        playlist_manager = PlaylistManager(cache_file, args.playlist_method)
    
    music = '/music'
    library = args.library
    failed_files = []

    # Check if the container music directory exists (not the host path)
    if not os.path.exists('/music'):
        logger.error("Music directory not found: /music")
        cli.show_error(f"Music directory not found: /music")
        sys.exit(1)

    start_time = time.time()
    try:
        # Clean up database
        logger.info("Cleaning up database - removing missing files")
        missing_in_db = audio_db.cleanup_database()
        if missing_in_db:
            logger.info(f"Removed {len(missing_in_db)} missing files from database")
            cli.show_warning(f"Removed {len(missing_in_db)} missing files from database")
            failed_files.extend(missing_in_db)

        # If --pipeline is set, run the full pipeline and exit
        if getattr(args, 'pipeline', False):
            logger.info("Running full pipeline mode")
            run_pipeline(args, audio_db, playlist_db, cli, stop_event=stop_event)
            logger.info("Pipeline mode completed")
            sys.exit(0)

        # Create a multiprocessing manager queue for long-running file notifications
        manager = multiprocessing.Manager()
        status_queue = manager.Queue()
        long_running_files = set()
        spinner_stop = threading.Event()

        def spinner_panel():
            if not long_running_files:
                return Panel("All files are processing normally.", title="Long-Running Files", border_style="green")
            return Panel(
                "\n".join([f"[yellow]{file}[/yellow]" for file in long_running_files]),
                title="[cyan]Long-Running Files (>5s) [spinner]",
                border_style="yellow"
            )

        def status_listener():
            while not spinner_stop.is_set():
                try:
                    filepath = status_queue.get(timeout=0.5)
                    long_running_files.add(filepath)
                except Exception:
                    continue

        listener_thread = threading.Thread(target=status_listener, daemon=True)
        listener_thread.start()

        if args.update:
            logger.info("Starting UPDATE mode - regenerating all playlists from database")
            cli.update_status("Running in UPDATE mode")
            features_from_db = audio_db.get_all_features()
            logger.info(f"Retrieved {len(features_from_db)} tracks from database for playlist generation")
            
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")
            
            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            
            # Save playlists to DB and to disk
            logger.info("Saving playlists to database")
            playlist_db.save_playlists(all_playlists)
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method, host_library=args.library)
            logger.info("UPDATE mode completed successfully")

        elif args.analyze or args.failed or args.force:
            logger.info(f"Starting ANALYSIS mode: analyze={args.analyze}, failed={args.failed}, force={args.force}")
            failed_files = run_analysis(args, audio_db, playlist_db, cli, stop_event=stop_event, force_reextract=args.no_cache)
            logger.info(f"Analysis completed with {len(failed_files)} failed files")

        elif args.generate_only:
            logger.info("Starting GENERATE_ONLY mode - creating playlists from existing analysis")
            cli.update_status("Generating playlists from database")
            features_from_db = audio_db.get_all_features()
            logger.info(f"Retrieved {len(features_from_db)} tracks from database for playlist generation")
            
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")
            
            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            
            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method, host_library=args.library)
            logger.info("GENERATE_ONLY mode completed successfully")

        else:
            logger.info("Starting FULL PIPELINE mode - analysis and playlist generation")
            cli.update_status("Running full processing pipeline")
            file_list = get_audio_files('/music')
            file_list = [convert_to_host_path(f, library, music) for f in file_list]
            logger.info(f"Processing {len(file_list)} audio files")
            
            # Analysis phase
            logger.info("Starting analysis phase")
            with CLIContextManager(cli, len(file_list), "[cyan]Analyzing audio files...") as (progress, task_id):
                processor = ParallelProcessor() if not sequential_mode else SequentialProcessor()
                workers = args.workers or max(1, mp.cpu_count())
                logger.debug(f"Using {workers} workers for analysis")
                
                for i, features in enumerate(processor.process(file_list, workers)):
                    # Show only the filename in the progress bar
                    if isinstance(features, tuple):
                        # SequentialProcessor yields (features, filepath)
                        _, filepath = features
                    else:
                        # ParallelProcessor yields features only, can't get filename
                        filepath = file_list[i] if i < len(file_list) else ""
                    filename = os.path.basename(filepath)
                    progress.update(task_id, advance=1, description=f"Analyzing: {filename} ({i+1}/{len(file_list)})")
                    if stop_event.is_set():
                        logger.info("Analysis interrupted by user")
                        print("\nInterrupted by user. Exiting...")
                        sys.exit(130)
                
                failed_files.extend(processor.failed_files)
                logger.info(f"Analysis phase completed. Processed {len(file_list)} files, {len(failed_files)} failed")
            
            # Generation phase
            logger.info("Starting playlist generation phase")
            features_from_db = audio_db.get_all_features()
            logger.info(f"Retrieved {len(features_from_db)} tracks from database for playlist generation")
            
            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")
                if stop_event.is_set():
                    logger.info("Playlist generation interrupted by user")
                    print("\nInterrupted by user. Exiting...")
                    sys.exit(130)
            
            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())
            
            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files, playlist_method=args.playlist_method, host_library=args.library)
            logger.info("FULL PIPELINE mode completed successfully")

        # Show failed files if any
        if failed_files:
            logger.warning(f"Showing {len(failed_files)} failed files")
            cli.show_file_errors(failed_files)

    except Exception as e:
        logger.error(f"Application error: {str(e)}")
        logger.error(f"Error traceback: {traceback.format_exc()}")
        cli.show_error(str(e), details=traceback.format_exc())
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("Application interrupted by user")
        print("\nInterrupted by user. Exiting...")
        stop_event.set()
        sys.exit(130)
    finally:
        # Only print summary for generate/update modes (not analyze_only)
        if not args.analyze:
            try:
                logger.debug("Calculating final summary statistics")
                features_from_db = audio_db.get_all_features()
                total_files = len(features_from_db)
                failed_count = len(failed_files)
                mb_count = 0
                no_mb_count = 0
                for f in features_from_db:
                    meta = f.get('metadata', {})
                    if meta.get('musicbrainz_id'):
                        mb_count += 1
                    else:
                        no_mb_count += 1
                
                runtime = time.time() - start_time
                logger.info(f"Final summary: Processed={total_files}, Failed={failed_count}, With MusicBrainz={mb_count}, Without MusicBrainz={no_mb_count}, Runtime={runtime:.1f}s")
                
                logger.debug(f"Processed Files: {total_files}")
                logger.debug(f"Failed Files: {failed_count}")
                logger.debug(f"With MusicBrainz Info: {mb_count}")
                logger.debug(f"Without MusicBrainz Info: {no_mb_count}")
                logger.debug(f"Runtime: {runtime:.1f} seconds")
                
            except Exception as e:
                logger.error(f"Error generating summary: {e}")

if __name__ == "__main__":
    main()