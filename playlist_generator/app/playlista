#!/usr/bin/env python3
"""
Main entry point for the playlist generator application.
"""

from music_analyzer.analysis_manager import run_analysis, run_pipeline
import signal
import logging as pylogging
from rich.spinner import Spinner
from rich.live import Live
import threading
import multiprocessing
from typing import Optional, List, Dict, Any
from rich.panel import Panel
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from utils.cli import PlaylistGeneratorCLI, CLIContextManager
from playlist_generator.playlist_manager import PlaylistManager
from playlist_generator.cache import CacheBasedGenerator
from playlist_generator.kmeans import KMeansPlaylistGenerator
from playlist_generator.time_based import TimeBasedScheduler
from music_analyzer.sequential import SequentialProcessor
from music_analyzer.parallel import ParallelProcessor
from database.playlist_db import PlaylistDatabase
from music_analyzer.feature_extractor import AudioAnalyzer
from utils.path_converter import PathConverter
from utils.path_utils import convert_to_host_path
from utils.logging_setup import setup_colored_logging, setup_queue_colored_logging
import multiprocessing as mp
import traceback
import time
import essentia
import logging
from utils.logging_setup import setup_colored_file_logging
import sys
import os
import argparse
from datetime import datetime

# Add the app directory to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Parse --log_level early to set LOG_LEVEL env var
pre_parser = argparse.ArgumentParser(add_help=False)
pre_parser.add_argument('--log_level', default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'])
pre_args, _ = pre_parser.parse_known_args(sys.argv[1:])
os.environ['LOG_LEVEL'] = pre_args.log_level

# Setup colored file logging

# Create log file path
log_dir = os.getenv('LOG_DIR', '/app/logs')
os.makedirs(log_dir, exist_ok=True)
# Use daily log rotation instead of per-run files
date_str = datetime.now().strftime('%Y%m%d')
log_file = os.path.join(log_dir, f'playlista_{date_str}.log')

# Setup colored logging to file only
setup_colored_file_logging(log_file)

logger = logging.getLogger(__name__)

# Add session separator to distinguish between runs
logger.info("=" * 80)
logger.info(
    f"PLAYLISTA SESSION STARTED - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
logger.info("=" * 80)

essentia.log.infoActive = False
essentia.log.warningActive = False
essentia.log.errorActive = False

# Logging is already set up above with setup_colored_file_logging(log_file)


# Logging already set up above

pylogging.getLogger("musicbrainzngs").setLevel(pylogging.WARNING)


def get_host_library_path() -> str:
    """Get the host library path from Docker volume mount."""
    # Try to get from environment variable first
    host_library = os.getenv('HOST_LIBRARY_PATH')
    if host_library:
        return host_library

    # Try to detect from /proc/mounts (Linux containers)
    try:
        with open('/proc/mounts', 'r') as f:
            for line in f:
                if '/music' in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        host_path = parts[0]
                        container_path = parts[1]
                        if container_path == '/music':
                            # Filter out loop devices and prefer actual host paths
                            if not host_path.startswith('/dev/loop'):
                                return host_path
                            # If we only find loop devices, try to resolve the real path
                            elif host_path.startswith('/dev/loop'):
                                # Try to get the real path from the loop device
                                try:
                                    import subprocess
                                    result = subprocess.run(['losetup', '-l'],
                                                            capture_output=True, text=True, timeout=5)
                                    if result.returncode == 0:
                                        for losetup_line in result.stdout.splitlines():
                                            if host_path in losetup_line:
                                                # Extract the backing file path
                                                parts = losetup_line.split()
                                                if len(parts) >= 7:  # Format: device backing_file
                                                    backing_file = parts[5]
                                                    # Extract the directory part
                                                    if '/music' in backing_file:
                                                        # Find the host path by removing the container path
                                                        host_dir = backing_file.replace(
                                                            '/music', '').rstrip('/')
                                                        if host_dir:
                                                            return host_dir
                                except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
                                    pass
    except (FileNotFoundError, PermissionError):
        pass

    # Try to get from Docker inspect (if available)
    try:
        import subprocess
        result = subprocess.run(['docker', 'inspect', '--format', '{{.Mounts}}', 'playlista'],
                                capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            # Parse the mount information
            mounts = result.stdout.strip()
            if '/music' in mounts:
                # Extract the host path from the mount info
                import re
                match = re.search(r'([^:]+):/music', mounts)
                if match:
                    return match.group(1)
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
        pass

    # Try to get from /proc/self/mountinfo (more detailed mount info)
    try:
        with open('/proc/self/mountinfo', 'r') as f:
            for line in f:
                if '/music' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        # Format: ID MAJOR:MINOR ROOT MOUNT_POINT OPTIONS
                        mount_point = parts[4]
                        if mount_point == '/music':
                            # The host path is in the root field (parts[3])
                            # But we need to resolve it properly
                            root_path = parts[3]
                            # This is complex - let's try a different approach
                            pass
    except (FileNotFoundError, PermissionError):
        pass

    # If all else fails, use the default
    return '/root/music/library'


# Initialize CLI
cli = PlaylistGeneratorCLI()

os.environ["ESSENTIA_LOGGING_LEVEL"] = "error"
os.environ["ESSENTIA_STREAM_LOGGING"] = "none"

cache_dir = os.getenv('CACHE_DIR', '/app/cache')
# Logging is handled by logging_setup.py - no need for duplicate setup


def get_audio_files(music_dir: str) -> List[str]:
    """Get audio files using the FileDiscovery module.

    Args:
        music_dir (str): Path to the music directory.

    Returns:
        List[str]: List of audio file paths.
    """
    from music_analyzer.file_discovery import FileDiscovery
    
    # Use FileDiscovery to get all valid audio files
    file_discovery = FileDiscovery(music_dir=music_dir)
    file_list = file_discovery.discover_files()
    
    logger.info(f"Found {len(file_list)} audio files in {music_dir}")
    return file_list


def save_playlists(playlists: Dict[str, Dict[str, Any]], output_dir: str, library: str, music: str, failed_files: List[str], playlist_method: Optional[str] = None, host_library: str = None) -> None:
    """Saves generated playlists to disk.

    Args:
        playlists (Dict[str, Dict[str, Any]]): Dictionary of playlist names to their data.
        output_dir (str): Root output directory.
        library (str): Path to the host's music directory.
        music (str): Path to the container's music directory.
        failed_files (List[str]): List of failed file paths.
        playlist_method (str | None): The method used to generate playlists (e.g., 'time', 'kmeans').
        host_library (str | None): Host library path for path conversion.
    """
    # For time-based, create subfolders per slot
    def get_time_slot_from_name(name: str) -> Optional[str]:
        if name.startswith("TimeSlot_"):
            slot_part = name[len("TimeSlot_"):]
            if "_Part" in slot_part:
                slot = slot_part.split("_Part")[0]
            else:
                slot = slot_part
            return slot
        return None

    # Initialize path converter
    path_converter = PathConverter(host_library or library, '/music')

    saved_count = 0
    for name, playlist_data in playlists.items():
        if 'tracks' not in playlist_data or not playlist_data['tracks']:
            continue

        # Determine output path
        playlist_out_dir = output_dir
        if playlist_method == 'time':
            slot = get_time_slot_from_name(name)
            if slot:
                playlist_out_dir = os.path.join(output_dir, slot)
        os.makedirs(playlist_out_dir, exist_ok=True)

        # Convert container paths to host paths using the path converter
        host_songs = path_converter.convert_playlist_tracks(
            playlist_data['tracks'])
        playlist_path = os.path.join(playlist_out_dir, f"{name}.m3u")
        with open(playlist_path, 'w') as f:
            f.write("\n".join(host_songs))
        saved_count += 1
        logger.debug(
            f"Saved {name} with {len(host_songs)} tracks to {playlist_path}")

    # Save failed files (keep at root of method dir)
    os.makedirs(output_dir, exist_ok=True)
    if failed_files:
        failed_path = os.path.join(output_dir, "Failed_Files.m3u")
        with open(failed_path, 'w') as f:
            host_failed = path_converter.convert_failed_files(failed_files)
            f.write("\n".join(host_failed))
        logger.info(f"Saved {len(failed_files)} failed files to {failed_path}")


def main() -> None:
    """Main entry point for the Playlista CLI application."""
    logger.info("Starting Playlista application")

    # Clear the terminal screen only if running interactively
    import sys
    if sys.stdout.isatty():
        os.system('cls' if os.name == 'nt' else 'clear')
    # Print Playlista ASCII art banner
    banner = r"""
  _                ___  __ ___     
 |_) |   /\ \_/ |   |  (_   |  /\  
 |   |_ /--\ |  |_ _|_ __)  | /--\ 
                                    
"""
    # ArgumentParser setup must come first
    parser = argparse.ArgumentParser(
        description='''
Playlista: Fast, flexible music playlist generator and analyzer.

- Analyze your music library for audio features
- Generate playlists using multiple methods (feature-group, time, kmeans, cache, tags)
- Designed for Docker and large libraries
''',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        epilog='''
Usage Tips:
  - All paths are fixed for Docker: /music, /app/playlists, /app/cache
  - Use --workers N for parallel processing (default: all CPUs)
  - Use --workers=1 for sequential processing (debugging/low memory)
  - Use --analyze to analyze new/changed files
  - Use --generate_only to generate playlists from existing analysis
  - Use --update to regenerate all playlists
  - Use --failed to re-analyze only failed tracks
  - Use --status to show library/database stats
  - Use --playlist_method to select playlist generation method
  - Use --min_tracks_per_genre for tag-based playlists

Examples:
  playlista --analyze --workers 8
  playlista --generate_only
  playlista --update
  playlista --analyze --workers=1
  playlista --playlist_method tags --min_tracks_per_genre 15
''')
    # -h/--help is available by default in argparse
    # Remove --music_dir argument
    # Rename --library to --library
    parser.add_argument('--library', default=get_host_library_path(),
                        help='Host music library directory (auto-detected from Docker volume mount)')
    # Output directory for playlists
    parser.add_argument(
        '--output_dir', default='/app/playlists', help='Output directory')
    # Cache directory
    parser.add_argument('--cache_dir', default='/app/cache',
                        help='Cache directory')
    # Number of playlists to generate
    parser.add_argument('--num_playlists', type=int, default=8,
                        help='Number of playlists to generate')
    # Number of workers for parallel processing
    parser.add_argument('--workers', type=int, default=None,
                        help='Number of workers (default: auto, use --workers=1 for sequential processing)')

    # Analyze files (default mode)
    parser.add_argument('-a', '--analyze', action='store_true',
                        help='Analyze files (see --failed and --force for options)')
    # Only generate playlists from database (no analysis)
    parser.add_argument('-g', '--generate_only', action='store_true',
                        help='Only generate playlists from database (no analysis)')
    # Update all playlists from database (no analysis, regenerates all playlists)
    parser.add_argument('-u', '--update', action='store_true',
                        help='Update all playlists from database (no analysis, regenerates all playlists)')
    # With --analyze: only re-analyze files previously marked as failed
    parser.add_argument('--failed', action='store_true',
                        help='With --analyze: only re-analyze files previously marked as failed')
    # Force re-analyze (used with --analyze)
    parser.add_argument('-f', '--force', action='store_true',
                        help='Force re-analyze (used with --analyze)')
    # Show library/database statistics and exit
    parser.add_argument('--status', action='store_true',
                        help='Show library/database statistics and exit')
    # Playlist generation method
    parser.add_argument('-m', '--playlist_method', choices=['all', 'time', 'kmeans', 'cache', 'tags'], default='all',
                        help='Playlist generation method: all (feature-group, default), time, kmeans, cache, or tags (genre+decade)')
    # Minimum number of tracks required for a genre to create a playlist (tags method only)
    parser.add_argument('--min_tracks_per_genre', type=int, default=10,
                        help='Minimum number of tracks required for a genre to create a playlist (tags method only)')
    # Set the logging level
    parser.add_argument('--log_level', default='INFO', choices=[
                        'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Set the logging level (default: INFO)')
    # Bypass the cache and re-extract features for all files
    parser.add_argument('--no_cache', action='store_true',
                        help='Bypass the cache and re-extract features for all files')
    # Run full pipeline: analyze, force, then failed
    parser.add_argument('--pipeline', action='store_true',
                        help='Run full pipeline: analyze, force, then failed')

    args = parser.parse_args()
    logger.info(f"Parsed arguments: analyze={args.analyze}, generate_only={args.generate_only}, update={args.update}, failed={args.failed}, force={args.force}, playlist_method={args.playlist_method}, workers={args.workers}")

    cache_dir = os.getenv('CACHE_DIR', '/app/cache')
    cache_file = os.path.join(cache_dir, 'audio_analysis.db')
    logger.debug(f"Using cache file: {cache_file}")

    console = Console()
    console.print(f"[bold magenta]{banner}[/bold magenta]")

    logger.info("Scanning music library for audio files")
    total_files = len(get_audio_files('/music'))
    logger.info(f"Found {total_files} audio files in library")

    # Initialize playlist_db and audio_db early for all modes
    logger.debug("Initializing database connections")
    playlist_db = PlaylistDatabase(cache_file)
    # AudioAnalyzer needs host library path for database storage, container music path for conversion
    audio_db = AudioAnalyzer(cache_file, library=args.library, music='/music')
    logger.debug("Database connections initialized")

    total_in_db = len(audio_db.get_all_features())
    logger.info(f"Database contains {total_in_db} analyzed tracks")

    # Initialize CLI
    cli = PlaylistGeneratorCLI()

    if args.pipeline:
        logger.info("Starting pipeline mode")
        from music_analyzer.analysis_manager import run_pipeline
        run_pipeline(args, audio_db, playlist_db,
                     cli)
        logger.info("Pipeline mode completed")
        sys.exit(0)

    os.environ["ESSENTIA_LOGGING_LEVEL"] = "error"
    os.environ["ESSENTIA_STREAM_LOGGING"] = "none"

    cache_dir = os.getenv('CACHE_DIR', '/app/cache')
    logfile_path = '/app/logs/playlista.log'
    logfile = open(logfile_path, 'a')
    os.dup2(logfile.fileno(), 2)  # Redirect fd 2 (stderr) at the OS level
    sys.stderr = logfile  # Also update Python's sys.stderr

    # Show configuration
    # Remove the call to cli.show_config

    # Initialize playlist manager
    # Pass min_tracks_per_genre to PlaylistManager if using tags method
    logger.info(
        f"Initializing playlist manager with method: {args.playlist_method}")
    if args.playlist_method == 'tags':
        playlist_manager = PlaylistManager(
            cache_file, args.playlist_method, min_tracks_per_genre=args.min_tracks_per_genre)
        logger.debug(
            f"Using tag-based playlist generation with min_tracks_per_genre: {args.min_tracks_per_genre}")
    else:
        playlist_manager = PlaylistManager(cache_file, args.playlist_method)

    music = '/music'
    library = args.library
    failed_files = []

    # Check if the container music directory exists (not the host path)
    if not os.path.exists('/music'):
        logger.error("Music directory not found: /music")
        cli.show_error(f"Music directory not found: /music")
        sys.exit(1)

    start_time = time.time()
    try:
        # Clean up database
        logger.info("Cleaning up database - removing missing files")
        missing_in_db = audio_db.cleanup_database()
        if missing_in_db:
            logger.info(
                f"Removed {len(missing_in_db)} missing files from database")
            cli.show_warning(
                f"Removed {len(missing_in_db)} missing files from database")
            failed_files.extend(missing_in_db)

        # Pipeline mode is handled earlier in the code

        # Create a multiprocessing manager queue for long-running file notifications
        manager = multiprocessing.Manager()
        status_queue = manager.Queue()
        long_running_files = set()
        spinner_stop = threading.Event()

        def spinner_panel():
            if not long_running_files:
                return Panel("All files are processing normally.", title="Long-Running Files", border_style="green")
            return Panel(
                "\n".join(
                    [f"[yellow]{file}[/yellow]" for file in long_running_files]),
                title="[cyan]Long-Running Files (>5s) [spinner]",
                border_style="yellow"
            )

        def status_listener():
            while not spinner_stop.is_set():
                try:
                    filepath = status_queue.get(timeout=0.5)
                    long_running_files.add(filepath)
                except Exception:
                    continue

        listener_thread = threading.Thread(target=status_listener, daemon=True)
        listener_thread.start()

        if args.update:
            logger.info(
                "Starting UPDATE mode - regenerating all playlists from database")
            cli.update_status("Running in UPDATE mode")
            features_from_db = audio_db.get_all_features()
            logger.info(
                f"Retrieved {len(features_from_db)} tracks from database for playlist generation")

            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(
                    features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")

            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())

            # Save playlists to DB and to disk
            logger.info("Saving playlists to database")
            playlist_db.save_playlists(all_playlists)
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(
                    args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files,
                           playlist_method=args.playlist_method, host_library=args.library)
            logger.info("UPDATE mode completed successfully")

        elif args.analyze or args.failed or args.force:
            logger.info(
                f"Starting ANALYSIS mode: analyze={args.analyze}, failed={args.failed}, force={args.force}")
            failed_files = run_analysis(
                args, audio_db, playlist_db, cli, force_reextract=args.no_cache)
            logger.info(
                f"Analysis completed with {len(failed_files)} failed files")

        elif args.generate_only:
            logger.info(
                "Starting GENERATE_ONLY mode - creating playlists from existing analysis")
            cli.update_status("Generating playlists from database")
            features_from_db = audio_db.get_all_features()
            logger.info(
                f"Retrieved {len(features_from_db)} tracks from database for playlist generation")

            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(
                    features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")

            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())

            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(
                    args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files,
                           playlist_method=args.playlist_method, host_library=args.library)
            logger.info("GENERATE_ONLY mode completed successfully")

        else:
            logger.info(
                "Starting FULL PIPELINE mode - analysis and playlist generation")
            cli.update_status("Running full processing pipeline")
            file_list = get_audio_files('/music')
            file_list = [convert_to_host_path(
                f, library, music) for f in file_list]
            logger.info(f"Processing {len(file_list)} audio files")

            # Analysis phase
            logger.info("Starting analysis phase")
            with CLIContextManager(cli, len(file_list), "[cyan]Analyzing audio files...") as (progress, task_id):
                processor = ParallelProcessor()
                workers = args.workers or max(1, mp.cpu_count())
                logger.debug(f"Using {workers} workers for analysis")

                for i, result in enumerate(processor.process(file_list, workers)):
                    # Both SequentialProcessor and ParallelProcessor yield (features, filepath, db_write_success)
                    if isinstance(result, tuple) and len(result) == 3:
                        _, filepath, _ = result
                    else:
                        # Fallback
                        filepath = file_list[i] if i < len(file_list) else ""
                    filename = os.path.basename(filepath)
                    progress.update(
                        task_id, advance=1, description=f"Analyzing: {filename} ({i+1}/{len(file_list)})")

                failed_files.extend(processor.failed_files)
                logger.info(
                    f"Analysis phase completed. Processed {len(file_list)} files, {len(failed_files)} failed")

            # Generation phase
            logger.info("Starting playlist generation phase")
            features_from_db = audio_db.get_all_features()
            logger.info(
                f"Retrieved {len(features_from_db)} tracks from database for playlist generation")

            with CLIContextManager(cli, 3, "[green]Generating playlists...") as (progress, task_id):
                logger.debug("Generating playlists from database features")
                all_playlists = playlist_manager.generate_playlists(
                    features_from_db, args.num_playlists)
                progress.update(task_id, advance=3)
                logger.info(f"Generated {len(all_playlists)} playlists")

            # Show playlist statistics
            logger.debug("Calculating and displaying playlist statistics")
            cli.show_playlist_stats(playlist_manager.get_playlist_stats())

            # Save playlists
            if args.playlist_method == 'tags':
                method_dir = os.path.join(args.output_dir, 'tags')
            else:
                method_dir = os.path.join(
                    args.output_dir, args.playlist_method)
            logger.info(f"Saving playlists to disk: {method_dir}")
            save_playlists(all_playlists, method_dir, library, music, failed_files,
                           playlist_method=args.playlist_method, host_library=args.library)
            logger.info("FULL PIPELINE mode completed successfully")

        # Show failed files if any
        if failed_files:
            logger.warning(f"Showing {len(failed_files)} failed files")
            cli.show_file_errors(failed_files)

    except Exception as e:
        logger.error(f"Application error: {str(e)}")
        logger.error(f"Error traceback: {traceback.format_exc()}")
        cli.show_error(str(e), details=traceback.format_exc())
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("Application interrupted by user")
        print("\nInterrupted by user. Exiting...")
        sys.exit(130)
    finally:
        # Only print summary for generate/update modes (not analyze_only)
        if not args.analyze:
            try:
                logger.debug("Calculating final summary statistics")
                features_from_db = audio_db.get_all_features()
                total_files = len(features_from_db)
                failed_count = len(failed_files)
                mb_count = 0
                no_mb_count = 0
                for f in features_from_db:
                    meta = f.get('metadata', {})
                    if meta.get('musicbrainz_id'):
                        mb_count += 1
                    else:
                        no_mb_count += 1

                runtime = time.time() - start_time
                logger.info(
                    f"Final summary: Processed={total_files}, Failed={failed_count}, With MusicBrainz={mb_count}, Without MusicBrainz={no_mb_count}, Runtime={runtime:.1f}s")

                logger.debug(f"Processed Files: {total_files}")
                logger.debug(f"Failed Files: {failed_count}")
                logger.debug(f"With MusicBrainz Info: {mb_count}")
                logger.debug(f"Without MusicBrainz Info: {no_mb_count}")
                logger.debug(f"Runtime: {runtime:.1f} seconds")

            except Exception as e:
                logger.error(f"Error generating summary: {e}")

        # Add session end marker
        logger.info("=" * 80)
        logger.info(
            f"PLAYLISTA SESSION ENDED - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 80)


if __name__ == "__main__":
    main()
